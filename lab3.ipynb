{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVsyGPllorS7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c14b2f6-5883-435d-c900-7d003ce614ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_OXP0PQpRxn"
      },
      "source": [
        "Switch to the project working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb5172o9oys5",
        "outputId": "8126c5c5-8607-49f1-94b3-fafde8650a25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/569 lab3/adversarial-yolo\n",
            " adversarial_examples.ipynb   image.py             predictions.jpg\n",
            " batch_detect.py              \u001b[0m\u001b[01;34minria\u001b[0m/               \u001b[01;34m__pycache__\u001b[0m/\n",
            " batch_rotate.py              lab3.ipynb           pytorch041_cuda92_colab.sh\n",
            " \u001b[01;34mcfg\u001b[0m/                         lab3.py              README.md\n",
            " cfg.py                       \u001b[01;34mlayers\u001b[0m/              recall.py\n",
            " class_only.json              LICENSE              region_loss.py\n",
            " class_shift.json             load_data.py         run_docker.sh\n",
            " clean_results.json           median_pool.py       \u001b[01;34msaved_patches\u001b[0m/\n",
            " craft_adv.py                 \u001b[01;34mmodels\u001b[0m/              \u001b[01;34mscripts\u001b[0m/\n",
            " darknet.py                   noise_results.json   \u001b[01;34mtest\u001b[0m/\n",
            " \u001b[01;34mdata\u001b[0m/                        \u001b[01;34mnon_printability\u001b[0m/    test_patch.py\n",
            " dataset.py                  \u001b[01;34m'oude versies'\u001b[0m/       \u001b[01;34mtools\u001b[0m/\n",
            " debug.py                     partial.py           train_patch.py\n",
            " demo.py                      patch_config.py      train.py\n",
            " detect.py                    \u001b[01;34mpatches\u001b[0m/             up_results.json\n",
            " \u001b[01;34mDGXContainer\u001b[0m/                patch.jpg            utils.py\n",
            " eval.py                      patch_results.json   valid.py\n",
            " Evaluation.ipynb             patch_simen.json     \u001b[01;34mweights\u001b[0m/\n",
            " FocalLoss.py                 patch_up.json        \u001b[01;34myolo-labels\u001b[0m/\n",
            " _gitignore                   \u001b[01;34mpersons\u001b[0m/\n",
            " how_to_debug.md              pr-curve.eps\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/569 lab3/adversarial-yolo/\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ril7SrNXpiKC"
      },
      "source": [
        "Install packages that you need here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zola2_M0owGl",
        "outputId": "6376185e-5da5-4a63-8785-5521d2979ba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.44.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tensorboardX\n",
        "!pip3 install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbLC9nU_OeL6"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyzJFl8ypqEp"
      },
      "source": [
        "## 2.1 Attack Human-Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX4vBER8p3RE"
      },
      "source": [
        "\n",
        "### (1) Detect without patch\n",
        "Utilize the apis in detect.py to recognize images of people. Feel free to edit the source code if itâ€™s needed. The result should be plotted after running the code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtHxSlg2qT_F",
        "outputId": "352edbb9-a299-410a-aca6-0acd7dcbc45e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer     filters    size              input                output\n",
            "    0 conv     32  3 x 3 / 1   608 x 608 x   3   ->   608 x 608 x  32\n",
            "    1 max          2 x 2 / 2   608 x 608 x  32   ->   304 x 304 x  32\n",
            "    2 conv     64  3 x 3 / 1   304 x 304 x  32   ->   304 x 304 x  64\n",
            "    3 max          2 x 2 / 2   304 x 304 x  64   ->   152 x 152 x  64\n",
            "    4 conv    128  3 x 3 / 1   152 x 152 x  64   ->   152 x 152 x 128\n",
            "    5 conv     64  1 x 1 / 1   152 x 152 x 128   ->   152 x 152 x  64\n",
            "    6 conv    128  3 x 3 / 1   152 x 152 x  64   ->   152 x 152 x 128\n",
            "    7 max          2 x 2 / 2   152 x 152 x 128   ->    76 x  76 x 128\n",
            "    8 conv    256  3 x 3 / 1    76 x  76 x 128   ->    76 x  76 x 256\n",
            "    9 conv    128  1 x 1 / 1    76 x  76 x 256   ->    76 x  76 x 128\n",
            "   10 conv    256  3 x 3 / 1    76 x  76 x 128   ->    76 x  76 x 256\n",
            "   11 max          2 x 2 / 2    76 x  76 x 256   ->    38 x  38 x 256\n",
            "   12 conv    512  3 x 3 / 1    38 x  38 x 256   ->    38 x  38 x 512\n",
            "   13 conv    256  1 x 1 / 1    38 x  38 x 512   ->    38 x  38 x 256\n",
            "   14 conv    512  3 x 3 / 1    38 x  38 x 256   ->    38 x  38 x 512\n",
            "   15 conv    256  1 x 1 / 1    38 x  38 x 512   ->    38 x  38 x 256\n",
            "   16 conv    512  3 x 3 / 1    38 x  38 x 256   ->    38 x  38 x 512\n",
            "   17 max          2 x 2 / 2    38 x  38 x 512   ->    19 x  19 x 512\n",
            "   18 conv   1024  3 x 3 / 1    19 x  19 x 512   ->    19 x  19 x1024\n",
            "   19 conv    512  1 x 1 / 1    19 x  19 x1024   ->    19 x  19 x 512\n",
            "   20 conv   1024  3 x 3 / 1    19 x  19 x 512   ->    19 x  19 x1024\n",
            "   21 conv    512  1 x 1 / 1    19 x  19 x1024   ->    19 x  19 x 512\n",
            "   22 conv   1024  3 x 3 / 1    19 x  19 x 512   ->    19 x  19 x1024\n",
            "   23 conv   1024  3 x 3 / 1    19 x  19 x1024   ->    19 x  19 x1024\n",
            "   24 conv   1024  3 x 3 / 1    19 x  19 x1024   ->    19 x  19 x1024\n",
            "   25 route  16\n",
            "   26 conv     64  1 x 1 / 1    38 x  38 x 512   ->    38 x  38 x  64\n",
            "   27 reorg              / 2    38 x  38 x  64   ->    19 x  19 x 256\n",
            "   28 route  27 24\n",
            "   29 conv   1024  3 x 3 / 1    19 x  19 x1280   ->    19 x  19 x1024\n",
            "   30 conv    425  1 x 1 / 1    19 x  19 x1024   ->    19 x  19 x 425\n",
            "   31 detection\n"
          ]
        }
      ],
      "source": [
        "# Your code starts here\n",
        "# Hint: To directly run the main function in a file, use \n",
        "%run detect.py cfg/yolov2.cfg weights/yolo.weights persons/person_001.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E31o5roroyh"
      },
      "source": [
        "### (2) Train patches\n",
        "Now we will train two patches by ourselves. One of the patches has a starter image as input and the other one is completely generated by our code. To do these, please \n",
        "\n",
        "\n",
        "*   Take a look at train_patch.py and edit the relevant code.\n",
        "*   Write a wrapped-up api for generating these two kinds of patches.\n",
        "*   Call the api to generate a with-starter-image patch and a without-starter-image patch.\n",
        "\n",
        "Please make sure to save these images since you need to use them in the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjXyqjr_s9ul"
      },
      "outputs": [],
      "source": [
        "def patch_training_caller(starter_img = none):\n",
        "  # Your code starts here\n",
        "  %run train_patch.py paper_obj starter_img #patches/object_score.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fl-Tqv0btOOb"
      },
      "outputs": [],
      "source": [
        "# Call patch_training_caller to generate a patch with starter image\n",
        "# Your code starts here\n",
        " %run patch_training_caller(starter_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLZyBqf5tORs"
      },
      "outputs": [],
      "source": [
        "# Call patch_training_caller to generate a patch without starter image\n",
        "# Your code starts here\n",
        " %run train_patch.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fKx3bN5uPTh"
      },
      "source": [
        "### (3) Detect people with patches\n",
        "Use the same api in detect.py as section 2.1 (1) to detect people who hold the patch picture you generated in 2.1 (2). The model should not recognize the people in this case. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYbls7kEugLg"
      },
      "outputs": [],
      "source": [
        "# Your code starts here\n",
        "%run detect.py cfg/yolov2.cfg weights/yolo.weights persons/person1_withstarter_1.jpg\n",
        "%run detect.py cfg/yolov2.cfg weights/yolo.weights persons/person1_withoutstarter_1.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcL-eMMzurSX"
      },
      "source": [
        "## 2.2 Attack Stop Signs-Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFhNYzc-uuAI"
      },
      "source": [
        "### (1) Detect without patch\n",
        "Similar to 2.1 (1), first we need to use apis in detect.py to recognize images of stop signs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOZ7-kthuzu2"
      },
      "outputs": [],
      "source": [
        "# Your code starts here\n",
        "%run detect.py cfg/yolov2.cfg weights/yolo.weights data/stop.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAFzefl4u1Ri"
      },
      "source": [
        "## (2) Patch stop signs\n",
        "* Edit the source code involved in the patch-sticking control flow to attach the patch image on all the stop sign images. Images belonging to any other class (i.e. people, horses, etc.) should not be patched.\n",
        "* Write a wrapped-up api for sticking patches on stop signs.\n",
        "* Call the api to stick patch on stop sign. You should specify which patch is used in parameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkmilxYP02VA"
      },
      "outputs": [],
      "source": [
        "def patch_sticking_caller(patch_img, ...):\n",
        "  # If there's no stop sign in the image, the image should not be patched.\n",
        "  # Your code starts here\n",
        "  %run python3 test_patch.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgGtiJw20HXP"
      },
      "outputs": [],
      "source": [
        "# Call patch_sticking_caller to stick a patch on stop sign image. \n",
        "# Your code starts here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYOEy7Ce0A0d"
      },
      "source": [
        "### (3) Detect stop sign with patch\n",
        "Use the same api in detect.py as section 2.2 (1) to detect the patched stop sign. The model should not recognize the stop sign in this case. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScyH85Oo0FF0"
      },
      "outputs": [],
      "source": [
        "# Your code starts here\n",
        "%run detect.py cfg/yolov2.cfg weights/yolo.weights testing/proper_patched/stop_patch.png"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lab3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}